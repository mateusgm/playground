{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.datasets import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "def d(data):\n",
    "    return [ \"%.2f\" % i for i in data ]\n",
    "\n",
    "def evaluate(coefs, x, y, logit=False):\n",
    "    y_pred = np.dot(x, coefs)\n",
    "    if(logit):\n",
    "        y_pred = sc.special.expit(y_pred)\n",
    "        return \"LL %.3f / AUC %.3f\" % ( log_loss(y, y_pred), roc_auc_score(y, y_pred))\n",
    "    return \"MSE %.3f / R2 %.3f\" % ( mean_squared_error(y, y_pred), r2_score(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = load_boston()\n",
    "df.data    = StandardScaler().fit_transform(df.data)\n",
    "df.classes = np.array([ int(y > np.mean(df.target)) for y in df.target ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def least_square_gradient(x, y, B, verbose=False):\n",
    "    loss = np.dot(x, B) - y \n",
    "    if(verbose): print \"MSE: \", np.mean(loss**2)\n",
    "    return np.dot(np.transpose(x), loss)\n",
    "\n",
    "def gradient_descent(x, y, gradient_func, learning_rate=.00001, max_iterations=1000):\n",
    "    coefs  = np.random.normal(size=x.shape[1])\n",
    "    _coefs = [0] * coefs.shape[0]\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        if np.all(coefs == _coefs): break\n",
    "        _coefs = coefs\n",
    "        coefs  = coefs - learning_rate * gradient_func(x, y, coefs)\n",
    "    \n",
    "    return coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  MSE 529.625 / R2 -5.274\n",
      "Gradient  MSE 529.625 / R2 -5.274\n"
     ]
    }
   ],
   "source": [
    "data = StandardScaler().fit_transform(bost.data)\n",
    "\n",
    "lr = LinearRegression().fit(data, df.target)\n",
    "print \"LR \", evaluate(lr.coef_, data, df.target)\n",
    "\n",
    "coefs = gradient_descent(data, df.target, least_square_gradient, learning_rate=.0005, max_iterations=1000)\n",
    "print \"Gradient \", evaluate(coefs, data, df.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5773603518468153"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy as sc\n",
    "\n",
    "def logit_likelihood(B, X, y, verbose=False):\n",
    "    eps = 1e-15\n",
    "    p   = sc.special.expit( np.dot(X,B) )\n",
    "    p   = np.array( [ min(eps, max(i, 1-eps)) for i in p ] )\n",
    "    ll  = y*np.log(p) + (1-y)*np.log(1.0-p)\n",
    "    return log_loss(y, p)\n",
    "\n",
    "def maximum_likelihood(X, y, likelihood_estimation):\n",
    "    init_B = np.random.normal(size=X.shape[1])\n",
    "    init_B = [0] * X.shape[1]\n",
    "    result = sc.optimize.minimize(logit_likelihood, x0=init_B, args=(X,y), method='Powell', options={ 'disp': True })\n",
    "    return result.x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  LL 0.332 / AUC 0.946\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 13.600808\n",
      "         Iterations: 1\n",
      "         Function evaluations: 176\n",
      "ML  LL 3.503 / AUC 0.301\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = LogisticRegression().fit(df.data, df.classes)\n",
    "print \"LR \", evaluate(lr.coef_[0], df.data, df.classes, logit=True)\n",
    "\n",
    "coefs = maximum_likelihood(df.data, df.classes, logit_likelihood)\n",
    "print \"ML \", evaluate(coefs, df.data, df.classes, logit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation Maximization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
