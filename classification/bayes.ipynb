{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.datasets import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.ensemble import *\n",
    "from operator import itemgetter, attrgetter, methodcaller\n",
    "\n",
    "def topk_acc(predictions, test, k=3):\n",
    "    pred = pd.DataFrame(predictions, columns=nb.classes_, index=test.index)\n",
    "    hits = 0\n",
    "    for i, row in pred.iterrows():\n",
    "        row = zip(row.index, list(row))\n",
    "        topk, prob = zip(*sorted(row, key=itemgetter(1), reverse=True)[:k])\n",
    "        if test['labelx'][i] in topk: hits += 1\n",
    "    return float(hits) / pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df    = fetch_20newsgroups()\n",
    "vec   = CountVectorizer(stop_words='english', max_features=500)\n",
    "X     = vec.fit_transform(df.data)\n",
    "vocab = vec.get_feature_names()\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data  = pd.DataFrame(X.todense(), columns=vocab)\n",
    "data['labelx']  = [ df.target_names[i] for i in df.target ]\n",
    "data['ranking'] = [ [ int(j == i) for j in range(len(df.target_names)) ] for i in df.target ]\n",
    "\n",
    "test_i = np.random.choice(data.index, size=int(data.shape[0]*.1), replace=False)\n",
    "test, train = data[np.in1d(data.index,test_i)], data[~np.in1d(data.index,test_i)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7957559681697612, 2.8001768346595934)"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB(alpha=1)\n",
    "nb.fit(train[vocab], train['labelx'])\n",
    "\n",
    "p1 = nb.predict_proba(test[vocab])\n",
    "topk_acc(p1, test, k=3), coverage_error(test['ranking'].tolist(), p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8585322723253758, 2.2307692307692308)"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = RandomForestClassifier(n_estimators=100, min_weight_fraction_leaf=.0005, n_jobs=-1)\n",
    "nb.fit(train[vocab], train['labelx'])\n",
    "\n",
    "p2 = nb.predict_proba(test[vocab])\n",
    "topk_acc(p2, test, k=3), coverage_error(test['ranking'].tolist(), p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8160919540229885, 2.4350132625994694)"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = SGDClassifier(alpha=.01, loss='log', penalty='elasticnet', l1_ratio=.0, n_jobs=-1)\n",
    "nb.fit(train[vocab], train['labelx'])\n",
    "\n",
    "p3 = nb.predict_proba(test[vocab])\n",
    "topk_acc(p3, test, k=3), coverage_error(test['ranking'].tolist(), p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.8 s, sys: 8.1 ms, total: 2.81 s\n",
      "Wall time: 2.82 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.14588859416445624, 10.426171529619806)"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xnb = MyNB()\n",
    "xnb.fit(train[vocab], train['labelx'])\n",
    "\n",
    "%time p = xnb.predict(test[vocab])\n",
    "topk_acc(p, test, k=3), coverage_error(test['ranking'].tolist(), p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class MyNB:\n",
    "    def __init__(self):\n",
    "        self.features = []\n",
    "        self.counts   = { \n",
    "            'n': 0, \n",
    "            'y': defaultdict(lambda: 0),\n",
    "            'x': defaultdict(lambda: defaultdict(lambda: 0)),\n",
    "            'x_y': defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: 0)))\n",
    "        }\n",
    "\n",
    "    def predict(self, data, classes=[]):\n",
    "        totals = []\n",
    "        for row in data.values:\n",
    "            probs = [ self.probs[\"{}_{}\".format('y', c)] for c in classes ]\n",
    "            for i, c in enumerate(classes):\n",
    "                probs[i] += np.sum([ self.probs[c][j][v] for j,v in enumerate(row) ])\n",
    "            totals.append(probs)\n",
    "        return totals\n",
    "        \n",
    "    def fit(self, data, labels, report_k=None):\n",
    "        for i, row in enumerate(data.values):\n",
    "            if report_k and self.counts['n'] % report_k == 0: print self.counts['n']\n",
    "            self.counts['n'] += 1\n",
    "            self.counts[ labels[i] ][ 0 ] += 1\n",
    "            for j, v in enumerate(row):\n",
    "                self.counts[ '_x_cnt_' ][ j ][ v ] += 1\n",
    "                self.counts[ labels[i] ][ j ][ v ] += 1\n",
    "        \n",
    "        for y, x in self.counts[ 'x_y' ].iteritems():\n",
    "            self.probs[y][0] = np.log(self._prior(y))\n",
    "            for j, posterior in x.iteritems():\n",
    "                self.probs[y][j] = defauctdict(lambda x: np.log(self._smoothing(y, j))) \n",
    "                for value, _ in posterior.iteritems():\n",
    "                    self.probs[y][j][value] = np.log(self._posterior(y, name, value))\n",
    "        \n",
    "    def _posterior(self, y, f, v):\n",
    "        return float( self.counts['x_y'][y][f][v] + 1 ) / ( len(self.counts['x'][f]) + self.counts['y'][y] ) \n",
    "    \n",
    "    def _smoothing(self, y, f ):\n",
    "        return 1.0 / ( len(self.counts['x'][f]) + self.counts['y'][y] )\n",
    "\n",
    "    def _prior(self, y):\n",
    "        return float( self.counts['y'][y] ) / self.counts['n']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.31 s, sys: 56.2 ms, total: 7.37 s\n",
      "Wall time: 7.4 s\n",
      "CPU times: user 14.1 ms, sys: 2.52 ms, total: 16.6 ms\n",
      "Wall time: 11.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8488063660477454, 2.6065428824049515)"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trainx(model, dataset, labels, classes):\n",
    "    for i, row in enumerate(dataset):\n",
    "        nb.partial_fit([row],[labels[i]], classes=classes)\n",
    "    return nb\n",
    "\n",
    "nb   = MultinomialNB(alpha=1)\n",
    "vals = train[vocab].values\n",
    "%time trainx(nb, vals, train['labelx'].values, df.target_names)\n",
    "\n",
    "%time p1 = nb.predict_proba(test[vocab])\n",
    "topk_acc(p1, test, k=3), coverage_error(test['ranking'].tolist(), p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
